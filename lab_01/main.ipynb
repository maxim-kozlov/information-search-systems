{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18aae8fb",
   "metadata": {},
   "source": [
    "# Ошибки токенизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b2a83aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymystem3 in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.10/site-packages (from pymystem3) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.10/site-packages (from requests->pymystem3) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.10/site-packages (from requests->pymystem3) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.10/site-packages (from requests->pymystem3) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.10/site-packages (from requests->pymystem3) (1.26.13)\n",
      "zsh:1: no matches found: pymorphy2[fast]\n",
      "Requirement already satisfied: razdel in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.10/site-packages (0.5.0)\n",
      "Requirement already satisfied: gensim in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.10/site-packages (4.3.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.10/site-packages (from gensim) (1.9.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.10/site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.10/site-packages (from gensim) (1.25.2)\n",
      "Requirement already satisfied: nltk in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.10/site-packages (from nltk) (2023.3.23)\n",
      "Requirement already satisfied: click in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: rusenttokenize in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.10/site-packages (0.0.5)\n",
      "Requirement already satisfied: regex in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.10/site-packages (2023.3.23)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymystem3\n",
    "!pip install pymorphy2[fast]\n",
    "!pip install razdel\n",
    "!pip install gensim\n",
    "!pip install nltk\n",
    "!pip install rusenttokenize\n",
    "!pip install regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f0fc879",
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel import sentenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36d50509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sents(sents):\n",
    "    for i, sent in enumerate(sents):\n",
    "        print(f\"{i}. {sent.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7eab77",
   "metadata": {},
   "source": [
    "## Ограничения\n",
    "Правила в Razdel оптимизированы для аккуратно написанных текстов с правильной пунктуацией. Решение хорошо работает с новостными статьями, художественными текстами. На постах из социальных сетей, расшифровках телефонных разговоров качество ниже.\n",
    "\n",
    "Если между предложениями нет пробела или в конце нет точки или предложение начинается с маленькой буквы, Razdel сделает ошибку.\n",
    "\n",
    "cc https://natasha.github.io/razdel/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f4e4a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Razdel - это профессиональная библиотека для обработки текста на русском языке.\n",
      "1. Она предоставляет мощные инструменты для токенизации, сегментации на предложения и слова, а также для работы с морфологией текста.\n",
      "2. Различные функции Razdel позволяют эффективно анализировать и обрабатывать текстовую информацию, что делает ее незаменимым инструментом в области обработки естественного языка на русском языке.\n"
     ]
    }
   ],
   "source": [
    "# текст сгенерирован гтп\n",
    "text = \"Razdel - это профессиональная библиотека для обработки текста на русском языке. Она предоставляет мощные инструменты для токенизации, сегментации на предложения и слова, а также для работы с морфологией текста. Различные функции Razdel позволяют эффективно анализировать и обрабатывать текстовую информацию, что делает ее незаменимым инструментом в области обработки естественного языка на русском языке.\"\n",
    "# list(map(lambda x: x.text, sentenize(text)))\n",
    "print_sents(sentenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23c722f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. На краю дороги стоял дуб.\n",
      "1. Вероятно, в десять раз старше берёз, составлявших лес, он был в десять раз толще и в два раза выше каждой берёзы.\n",
      "2. Это был огромный в два обхвата дуб с обломанными, давно видно, суками и с обломанной корой, заросшей старыми болячками.\n",
      "3. С огромными своими неуклюжими, несимметрично-растопыренными, корявыми руками и пальцами, он старым, сердитым и презрительным уродом стоял между улыбающимися берёзами.\n",
      "4. Только он один не хотел подчиняться обаянию весны и не хотел видеть ни весны, ни солнца.\n",
      "5. «Весна, и любовь, и счастие!» – как будто говорил этот дуб, – «и как не надоест вам всё один и тот же глупый и бессмысленный обман.\n",
      "6. Всё одно и то же, и всё обман!\n",
      "7. Нет ни весны, ни солнца, ни счастия.\n",
      "8. Вон смотрите, сидят задавленные мёртвые ели, всегда одинакие, и вон и я растопырил свои обломанные, ободранные пальцы, где ни выросли они – из спины, из боков; как выросли – так и стою, и не верю вашим надеждам и обманам».\n",
      "9. Князь Андрей несколько раз оглянулся на этот дуб, проезжая по лесу, как будто он чего-то ждал от него.\n",
      "10. Цветы и трава были и под дубом, но он всё так же, хмурясь, неподвижно, уродливо и упорно, стоял посреди их.\n",
      "11. «Да, он прав, тысячу раз прав этот дуб, думал князь Андрей, пускай другие, молодые, вновь поддаются на этот обман, а мы знаем жизнь, – наша жизнь кончена!»\n",
      "12. Целый новый ряд мыслей безнадёжных, но грустно-приятных в связи с этим дубом, возник в душе князя Андрея.\n",
      "13. Во время этого путешествия он как будто вновь обдумал всю свою жизнь, и пришёл к тому же прежнему успокоительному и безнадёжному заключению, что ему начинать ничего было не надо, что он должен доживать свою жизнь, не делая зла, не тревожась и ничего не желая.\n"
     ]
    }
   ],
   "source": [
    "# война и мир\n",
    "text = \"\"\"На краю дороги стоял дуб. Вероятно, в десять раз старше берёз, составлявших лес, он был в десять раз толще и в два раза выше каждой берёзы. Это был огромный в два обхвата дуб с обломанными, давно видно, суками и с обломанной корой, заросшей старыми болячками. С огромными своими неуклюжими, несимметрично-растопыренными, корявыми руками и пальцами, он старым, сердитым и презрительным уродом стоял между улыбающимися берёзами. Только он один не хотел подчиняться обаянию весны и не хотел видеть ни весны, ни солнца.\n",
    "\n",
    "«Весна, и любовь, и счастие!» – как будто говорил этот дуб, – «и как не надоест вам всё один и тот же глупый и бессмысленный обман. Всё одно и то же, и всё обман! Нет ни весны, ни солнца, ни счастия. Вон смотрите, сидят задавленные мёртвые ели, всегда одинакие, и вон и я растопырил свои обломанные, ободранные пальцы, где ни выросли они – из спины, из боков; как выросли – так и стою, и не верю вашим надеждам и обманам».\n",
    "\n",
    "Князь Андрей несколько раз оглянулся на этот дуб, проезжая по лесу, как будто он чего-то ждал от него. Цветы и трава были и под дубом, но он всё так же, хмурясь, неподвижно, уродливо и упорно, стоял посреди их. «Да, он прав, тысячу раз прав этот дуб, думал князь Андрей, пускай другие, молодые, вновь поддаются на этот обман, а мы знаем жизнь, – наша жизнь кончена!» Целый новый ряд мыслей безнадёжных, но грустно-приятных в связи с этим дубом, возник в душе князя Андрея. Во время этого путешествия он как будто вновь обдумал всю свою жизнь, и пришёл к тому же прежнему успокоительному и безнадёжному заключению, что ему начинать ничего было не надо, что он должен доживать свою жизнь, не делая зла, не тревожась и ничего не желая.\n",
    "\"\"\"\n",
    "print_sents(sentenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eca3d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Сейчас.\n",
      "1. A propos, — прибавила она, опять успокоиваясь, — нынче у меня два очень интересные человека, le vicomte de Mortemart, il est allié aux Montmorency par les Rohans 10, одна из лучших фамилий Франции.\n",
      "2. Это один из хороших эмигрантов, из настоящих.\n",
      "3. И потом l'abbé Morio; вы знаете этот глубокий ум?\n",
      "4. Он был принят государем.\n",
      "5. Вы знаете?\n"
     ]
    }
   ],
   "source": [
    "text = \"Сейчас. A propos, — прибавила она, опять успокоиваясь, — нынче у меня два очень интересные человека, le vicomte de Mortemart, il est allié aux Montmorency par les Rohans 10, одна из лучших фамилий Франции. Это один из хороших эмигрантов, из настоящих. И потом l'abbé Morio; вы знаете этот глубокий ум? Он был принят государем. Вы знаете?\"\n",
    "print_sents(sentenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "added911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. К любым\n",
      "     чертям с матерями\n",
      "               катись\n",
      "любая бумажка.\n",
      "1. Но эту…\n",
      "2. Я\n",
      " достаю\n",
      "     из широких штанин\n",
      "дубликатом\n",
      "      бесценного груза.\n",
      "3. Читайте,\n",
      "     завидуйте,\n",
      "           я —\n",
      "             гражданин\n",
      "Советского Союза.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "К любым\n",
    "     чертям с матерями\n",
    "               катись\n",
    "любая бумажка.\n",
    "        Но эту…\n",
    "Я\n",
    " достаю\n",
    "     из широких штанин\n",
    "дубликатом\n",
    "      бесценного груза.\n",
    "Читайте,\n",
    "     завидуйте,\n",
    "           я —\n",
    "             гражданин\n",
    "Советского Союза.\n",
    "\"\"\"\n",
    "print_sents(sentenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f6c28d",
   "metadata": {},
   "source": [
    "## А теперь ломаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed14e058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. На краю дороги стоял дуб.\n",
      "1. Вероятно, в десять раз старше берёз, составлявших лес, он был в десять раз толще и в два раза выше каждой берёзы.\n"
     ]
    }
   ],
   "source": [
    "text = \"На краю дороги стоял дуб. Вероятно, в десять раз старше берёз, составлявших лес, он был в десять раз толще и в два раза выше каждой берёзы.\"\n",
    "print_sents(sentenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a39ac062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. На краю дороги стоял дуб. вероятно, в десять раз старше берёз, составлявших лес, он был в десять раз толще и в два раза выше каждой берёзы.\n"
     ]
    }
   ],
   "source": [
    "text = \"На краю дороги стоял дуб. вероятно, в десять раз старше берёз, составлявших лес, он был в десять раз толще и в два раза выше каждой берёзы.\"\n",
    "print_sents(sentenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60e85bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. На краю дороги стоял дуб.Вероятно, в десять раз старше берёз, составлявших лес, он был в десять раз толще и в два раза выше каждой берёзы.\n"
     ]
    }
   ],
   "source": [
    "text = \"На краю дороги стоял дуб.Вероятно, в десять раз старше берёз, составлявших лес, он был в десять раз толще и в два раза выше каждой берёзы.\"\n",
    "print_sents(sentenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2a106bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. На краю дороги стоял дуб .Вероятно, в десять раз старше берёз, составлявших лес, он был в десять раз толще и в два раза выше каждой берёзы.\n"
     ]
    }
   ],
   "source": [
    "text = \"На краю дороги стоял дуб .Вероятно, в десять раз старше берёз, составлявших лес, он был в десять раз толще и в два раза выше каждой берёзы.\"\n",
    "print_sents(sentenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b32e234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. На краю дороги стоял дуб Вероятно, в десять раз старше берёз, составлявших лес, он был в десять раз толще и в два раза выше каждой берёзы.\n"
     ]
    }
   ],
   "source": [
    "text = \"На краю дороги стоял дуб Вероятно, в десять раз старше берёз, составлявших лес, он был в десять раз толще и в два раза выше каждой берёзы.\"\n",
    "print_sents(sentenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "48d700f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. 1. Текст юридической нормы согласно постановлению Правительства РФ от 25.05.2020 №3543 \"О размещении информации и т.д.\n",
      "1. Общие положения\" (зарегистрировано Министервом юстиции РФ.\n",
      "2. Регистрационный номер 3333) выделяются М.М. Мишустиным следующие истории: \n",
      "1.\n",
      "3. История 1;\n",
      "4. 2. История 2;\n",
      "5. 3.2. История 3\n",
      "а) История 2.\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/natasha/razdel/issues/11\n",
    "text = \"\"\"1. Текст юридической нормы согласно постановлению Правительства РФ от 25.05.2020 №3543 \"О размещении информации и т.д. Общие положения\" (зарегистрировано Министервом юстиции РФ. Регистрационный номер 3333) выделяются М.М. Мишустиным следующие истории: \\n1. История 1; \\n2. История 2; \\n3.2. История 3\\nа) История 2.\"\"\"\n",
    "print_sents(sentenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e288c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Существующие ГИС:\n",
      "1) ArcGIS;\n",
      "1. 2) GRASS;\n",
      "2. 3) QGIS.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Существующие ГИС:\n",
    "1) ArcGIS;\n",
    "2) GRASS;\n",
    "3) QGIS.\n",
    "\"\"\"\n",
    "print_sents(sentenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e239758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Мда, – мычал Иван Иванович, тонкий белокурый вьюн с ехидною бородкой, делавшей его похожим на американца времен Линкольна (он поминутно захватывал ее в горсть и ловил ее кончик губами).\n",
      "1. – Я, конечно, молчу.\n",
      "2. Вы сами понимаете – я смотрю на эти вещи совершенно иначе.\n",
      "3. Да, кстати.\n",
      "4. Расскажите, как вас расстригали.\n",
      "5. Я давно хотел спросить.\n",
      "6. Небось перетрухнули?\n",
      "7. Анафеме вас предавали?\n",
      "8. А?\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/mannefedov/compling_nlp_hse_course/blob/master/data/zhivago.txt\n",
    "text = \"\"\"\n",
    "Мда, – мычал Иван Иванович, тонкий белокурый вьюн с ехидною бородкой, делавшей его похожим на американца времен Линкольна (он поминутно захватывал ее в горсть и ловил ее кончик губами). – Я, конечно, молчу. Вы сами понимаете – я смотрю на эти вещи совершенно иначе. Да, кстати. Расскажите, как вас расстригали. Я давно хотел спросить. Небось перетрухнули? Анафеме вас предавали? А?\n",
    "\"\"\"\n",
    "print_sents(sentenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb30da45",
   "metadata": {},
   "source": [
    "## Токенизация Mystem vs razdel.tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e81107f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Лично у меня zero-shot классификация на базе NLI не особо взлетела.\n",
      "1. Например, на задаче классификации 68 интентов zero-shot классификация на основе NLI с написанными вручную 68 гипотезами для каждого класса отработала хуже, чем метод ближайших соседей на эмбеддингах LaBSE с всего лишь тремя примерами на каждый класс.\n",
      "2. На задачах классификации тональности и токсичности подход Labse+KNN тоже сравнялся по качеству с NLI+zero-shot на нескольких десятках размеченных примеров.\n",
      "3. Поэтому кажется, что zero-shot классификацию стоит применять только в случаях, когда нет возможности собрать даже небольшую обучающую выборку, и что её качество будет сильно зависеть от выбранных названий классов и от того, какой шаблон используется для гипотез.\n",
      "4. Поэтому, если есть возможность дообучить свою модель на задачу классификации, лучше дообучайте.\n",
      "5. Если возможности нет, но есть даже небольшое число размеченных примеров, используйте KNN.\n",
      "6. А к zero-shot прибегайте только в крайних случаях.\n",
      "7. Впрочем, несмотря на свою относительную бесполезность, zero-shot классификация – это всё равно очень прикольно.\n",
      "8. Насколько мне известно, сегодня существует два датасета, посвящённых задаче NLI на русском языке: TERRa, собранная из русскоязычных публикаций и вручную размеченная, и XNLI, где английские размеченные тексты были переведены на русский и ряд других языков.\n",
      "9. Оба эти датасета не очень большие, зато на английском языке существуют буквально миллионы размеченных пар текстов.\n",
      "10. Поэтому в качестве обучающей выборки я использовал в основном корпусы, машинно переведённые с английского языка.\n",
      "11. Большинство из них было взято из репозитория Felipe Salvatore.\n"
     ]
    }
   ],
   "source": [
    "# https://habr.com/ru/articles/582620/\n",
    "text = \"\"\"\n",
    "Лично у меня zero-shot классификация на базе NLI не особо взлетела. Например, на задаче классификации 68 интентов zero-shot классификация на основе NLI с написанными вручную 68 гипотезами для каждого класса отработала хуже, чем метод ближайших соседей на эмбеддингах LaBSE с всего лишь тремя примерами на каждый класс. На задачах классификации тональности и токсичности подход Labse+KNN тоже сравнялся по качеству с NLI+zero-shot на нескольких десятках размеченных примеров.\n",
    "Поэтому кажется, что zero-shot классификацию стоит применять только в случаях, когда нет возможности собрать даже небольшую обучающую выборку, и что её качество будет сильно зависеть от выбранных названий классов и от того, какой шаблон используется для гипотез. Поэтому, если есть возможность дообучить свою модель на задачу классификации, лучше дообучайте. Если возможности нет, но есть даже небольшое число размеченных примеров, используйте KNN. А к zero-shot прибегайте только в крайних случаях.\n",
    "Впрочем, несмотря на свою относительную бесполезность, zero-shot классификация – это всё равно очень прикольно.\n",
    "Насколько мне известно, сегодня существует два датасета, посвящённых задаче NLI на русском языке: TERRa, собранная из русскоязычных публикаций и вручную размеченная, и XNLI, где английские размеченные тексты были переведены на русский и ряд других языков. Оба эти датасета не очень большие, зато на английском языке существуют буквально миллионы размеченных пар текстов. Поэтому в качестве обучающей выборки я использовал в основном корпусы, машинно переведённые с английского языка. Большинство из них было взято из репозитория Felipe Salvatore.\n",
    "\"\"\"\n",
    "print_sents(sentenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27016f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing mystem to /Users/maxkozlov/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-macosx.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import pymystem3\n",
    "# pymystem3.constants.MYSTEM_DIR = '/Volumes/TOSHIBA EXT/repos/bmstu/ИПС/bin'\n",
    "# pymystem3.constants.MYSTEM_BIN = '/Volumes/TOSHIBA EXT/repos/bmstu/ИПС/bin/mystem'\n",
    "\n",
    "mystem = pymystem3.Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f39e724a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Лично', 'у', 'меня', 'zero-shot', 'классификация', 'на', 'базе', 'NLI', 'не', 'особо', 'взлетела', '.', 'Например', ',', 'на']\n"
     ]
    }
   ],
   "source": [
    "import razdel\n",
    "print(list(map(lambda x: x.text, razdel.tokenize(text)))[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5bb5e158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Лично', 'у', 'меня', 'классификация', 'на', 'базе', 'не', 'особо', 'взлетела', 'Например', 'на', 'задаче', 'классификации', 'интентов', 'классификация']\n"
     ]
    }
   ],
   "source": [
    "words_analized = mystem.analyze(text)\n",
    "words_analized_norm = [\n",
    "    words\n",
    "    for words in words_analized\n",
    "    if words.get('analysis')\n",
    "]\n",
    "print(list(map(lambda x: x['text'], words_analized_norm[:15])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee03aff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['лично', 'у', 'я', 'классификация', 'на', 'база', 'не', 'особо', 'взлетать', 'например', 'на', 'задача', 'классификация', 'интент', 'классификация']\n"
     ]
    }
   ],
   "source": [
    "print(list(map(lambda x: x['analysis'][0]['lex'], words_analized_norm[:15])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d69c979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'лично', 'wt': 0.959131173, 'gr': 'ADV='}],\n",
       "  'text': 'Лично'},\n",
       " {'analysis': [{'lex': 'у', 'wt': 0.9993940324, 'gr': 'PR='}], 'text': 'у'},\n",
       " {'analysis': [{'lex': 'я',\n",
       "    'wt': 0.9999549915,\n",
       "    'gr': 'SPRO,ед,1-л=(вин|род)'}],\n",
       "  'text': 'меня'},\n",
       " {'analysis': [{'lex': 'классификация', 'wt': 1, 'gr': 'S,жен,неод=им,ед'}],\n",
       "  'text': 'классификация'},\n",
       " {'analysis': [{'lex': 'на', 'wt': 0.9989522965, 'gr': 'PR='}], 'text': 'на'},\n",
       " {'analysis': [{'lex': 'база',\n",
       "    'wt': 0.993192315,\n",
       "    'gr': 'S,жен,неод=(пр,ед|дат,ед)'}],\n",
       "  'text': 'базе'},\n",
       " {'analysis': [{'lex': 'не', 'wt': 1, 'gr': 'PART='}], 'text': 'не'},\n",
       " {'analysis': [{'lex': 'особо', 'wt': 0.9697823395, 'gr': 'ADV='}],\n",
       "  'text': 'особо'},\n",
       " {'analysis': [{'lex': 'взлетать',\n",
       "    'wt': 1,\n",
       "    'gr': 'V,нп=прош,ед,изъяв,жен,сов'}],\n",
       "  'text': 'взлетела'},\n",
       " {'analysis': [{'lex': 'например', 'wt': 1, 'gr': 'ADV,вводн='}],\n",
       "  'text': 'Например'},\n",
       " {'analysis': [{'lex': 'на', 'wt': 0.9989522965, 'gr': 'PR='}], 'text': 'на'},\n",
       " {'analysis': [{'lex': 'задача', 'wt': 1, 'gr': 'S,жен,неод=(пр,ед|дат,ед)'}],\n",
       "  'text': 'задаче'},\n",
       " {'analysis': [{'lex': 'классификация',\n",
       "    'wt': 1,\n",
       "    'gr': 'S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн)'}],\n",
       "  'text': 'классификации'},\n",
       " {'analysis': [{'lex': 'интент',\n",
       "    'wt': 1,\n",
       "    'qual': 'bastard',\n",
       "    'gr': 'S,муж,неод=род,мн'}],\n",
       "  'text': 'интентов'},\n",
       " {'analysis': [{'lex': 'классификация', 'wt': 1, 'gr': 'S,жен,неод=им,ед'}],\n",
       "  'text': 'классификация'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_analized_norm[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d02922d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Лично', 'у', 'меня', 'zero-shot', 'классификация', 'на', 'базе', 'NLI', 'не', 'особо', 'взлетела', '.', 'Например', ',', 'на', 'задаче', 'классификации', '68', 'интентов', 'zero-shot', 'классификация', 'на', 'основе', 'NLI', 'с', 'написанными', 'вручную', '68', 'гипотезами', 'для', 'каждого', 'класса', 'отработала', 'хуже', ',', 'чем', 'метод', 'ближайших', 'соседей', 'на', 'эмбеддингах', 'LaBSE', 'с', 'всего', 'лишь', 'тремя', 'примерами', 'на', 'каждый', 'класс', '.', 'На', 'задачах', 'классификации', 'тональности', 'и', 'токсичности', 'подход', 'Labse', '+', 'KNN', 'тоже', 'сравнялся', 'по', 'качеству', 'с', 'NLI', '+', 'zero-shot', 'на', 'нескольких', 'десятках', 'размеченных', 'примеров', '.', 'Поэтому', 'кажется', ',', 'что', 'zero-shot', 'классификацию', 'стоит', 'применять', 'только', 'в', 'случаях', ',', 'когда', 'нет', 'возможности', 'собрать', 'даже', 'небольшую', 'обучающую', 'выборку', ',', 'и', 'что', 'её', 'качество', 'будет', 'сильно', 'зависеть', 'от', 'выбранных', 'названий', 'классов', 'и', 'от', 'того', ',', 'какой', 'шаблон', 'используется', 'для', 'гипотез', '.', 'Поэтому', ',', 'если', 'есть', 'возможность', 'дообучить', 'свою', 'модель', 'на', 'задачу', 'классификации', ',', 'лучше', 'дообучайте', '.', 'Если', 'возможности', 'нет', ',', 'но', 'есть', 'даже', 'небольшое', 'число', 'размеченных', 'примеров', ',', 'используйте', 'KNN', '.', 'А', 'к', 'zero-shot', 'прибегайте', 'только', 'в', 'крайних', 'случаях', '.', 'Впрочем', ',', 'несмотря', 'на', 'свою', 'относительную', 'бесполезность', ',', 'zero-shot', 'классификация', '–', 'это', 'всё', 'равно', 'очень', 'прикольно', '.', 'Насколько', 'мне', 'известно', ',', 'сегодня', 'существует', 'два', 'датасета', ',', 'посвящённых', 'задаче', 'NLI', 'на', 'русском', 'языке', ':', 'TERRa', ',', 'собранная', 'из', 'русскоязычных', 'публикаций', 'и', 'вручную', 'размеченная', ',', 'и', 'XNLI', ',', 'где', 'английские', 'размеченные', 'тексты', 'были', 'переведены', 'на', 'русский', 'и', 'ряд', 'других', 'языков', '.', 'Оба', 'эти', 'датасета', 'не', 'очень', 'большие', ',', 'зато', 'на', 'английском', 'языке', 'существуют', 'буквально', 'миллионы', 'размеченных', 'пар', 'текстов', '.', 'Поэтому', 'в', 'качестве', 'обучающей', 'выборки', 'я', 'использовал', 'в', 'основном', 'корпусы', ',', 'машинно', 'переведённые', 'с', 'английского', 'языка', '.', 'Большинство', 'из', 'них', 'было', 'взято', 'из', 'репозитория', 'Felipe', 'Salvatore', '.']\n"
     ]
    }
   ],
   "source": [
    "print(list(map(lambda x: x.text, razdel.tokenize(text))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "723fe8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Лично', 'у', 'меня', 'классификация', 'на', 'базе', 'не', 'особо', 'взлетела', 'Например', 'на', 'задаче', 'классификации', 'интентов', 'классификация', 'на', 'основе', 'с', 'написанными', 'вручную', 'гипотезами', 'для', 'каждого', 'класса', 'отработала', 'хуже', 'чем', 'метод', 'ближайших', 'соседей', 'на', 'эмбеддингах', 'с', 'всего', 'лишь', 'тремя', 'примерами', 'на', 'каждый', 'класс', 'На', 'задачах', 'классификации', 'тональности', 'и', 'токсичности', 'подход', 'тоже', 'сравнялся', 'по', 'качеству', 'с', 'на', 'нескольких', 'десятках', 'размеченных', 'примеров', 'Поэтому', 'кажется', 'что', 'классификацию', 'стоит', 'применять', 'только', 'в', 'случаях', 'когда', 'нет', 'возможности', 'собрать', 'даже', 'небольшую', 'обучающую', 'выборку', 'и', 'что', 'её', 'качество', 'будет', 'сильно', 'зависеть', 'от', 'выбранных', 'названий', 'классов', 'и', 'от', 'того', 'какой', 'шаблон', 'используется', 'для', 'гипотез', 'Поэтому', 'если', 'есть', 'возможность', 'дообучить', 'свою', 'модель', 'на', 'задачу', 'классификации', 'лучше', 'дообучайте', 'Если', 'возможности', 'нет', 'но', 'есть', 'даже', 'небольшое', 'число', 'размеченных', 'примеров', 'используйте', 'А', 'к', 'прибегайте', 'только', 'в', 'крайних', 'случаях', 'Впрочем', 'несмотря', 'на', 'свою', 'относительную', 'бесполезность', 'классификация', 'это', 'всё', 'равно', 'очень', 'прикольно', 'Насколько', 'мне', 'известно', 'сегодня', 'существует', 'два', 'датасета', 'посвящённых', 'задаче', 'на', 'русском', 'языке', 'собранная', 'из', 'русскоязычных', 'публикаций', 'и', 'вручную', 'размеченная', 'и', 'где', 'английские', 'размеченные', 'тексты', 'были', 'переведены', 'на', 'русский', 'и', 'ряд', 'других', 'языков', 'Оба', 'эти', 'датасета', 'не', 'очень', 'большие', 'зато', 'на', 'английском', 'языке', 'существуют', 'буквально', 'миллионы', 'размеченных', 'пар', 'текстов', 'Поэтому', 'в', 'качестве', 'обучающей', 'выборки', 'я', 'использовал', 'в', 'основном', 'корпусы', 'машинно', 'переведённые', 'с', 'английского', 'языка', 'Большинство', 'из', 'них', 'было', 'взято', 'из', 'репозитория']\n"
     ]
    }
   ],
   "source": [
    "print(list(map(lambda x: x['text'], words_analized_norm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ae07bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['лично', 'у', 'я', 'классификация', 'на', 'база', 'не', 'особо', 'взлетать', 'например', 'на', 'задача', 'классификация', 'интент', 'классификация', 'на', 'основа', 'с', 'написать', 'вручную', 'гипотеза', 'для', 'каждый', 'класс', 'отрабатывать', 'плохой', 'чем', 'метод', 'близкий', 'сосед', 'на', 'эмбеддинг', 'с', 'всего', 'лишь', 'три', 'пример', 'на', 'каждый', 'класс', 'на', 'задача', 'классификация', 'тональность', 'и', 'токсичность', 'подход', 'тоже', 'сравниваться', 'по', 'качество', 'с', 'на', 'несколько', 'десяток', 'размечать', 'пример', 'поэтому', 'казаться', 'что', 'классификация', 'стоить', 'применять', 'только', 'в', 'случай', 'когда', 'нет', 'возможность', 'собирать', 'даже', 'небольшой', 'обучать', 'выборка', 'и', 'что', 'ее', 'качество', 'быть', 'сильно', 'зависеть', 'от', 'выбирать', 'название', 'класс', 'и', 'от', 'то', 'какой', 'шаблон', 'использоваться', 'для', 'гипотеза', 'поэтому', 'если', 'быть', 'возможность', 'дообучать', 'свой', 'модель', 'на', 'задача', 'классификация', 'хорошо', 'дообучать', 'если', 'возможность', 'нет', 'но', 'быть', 'даже', 'небольшой', 'число', 'размечать', 'пример', 'использовать', 'а', 'к', 'прибегать', 'только', 'в', 'крайний', 'случай', 'впрочем', 'несмотря', 'на', 'свой', 'относительный', 'бесполезность', 'классификация', 'это', 'все', 'равный', 'очень', 'прикольно', 'насколько', 'я', 'известно', 'сегодня', 'существовать', 'два', 'датасет', 'посвящать', 'задача', 'на', 'русский', 'язык', 'собирать', 'из', 'русскоязычный', 'публикация', 'и', 'вручную', 'размечать', 'и', 'где', 'английский', 'размечать', 'текст', 'быть', 'переводить', 'на', 'русский', 'и', 'ряд', 'другой', 'язык', 'оба', 'этот', 'датасет', 'не', 'очень', 'большой', 'зато', 'на', 'английский', 'язык', 'существовать', 'буквально', 'миллион', 'размечать', 'пара', 'текст', 'поэтому', 'в', 'качество', 'обучать', 'выборка', 'я', 'использовать', 'в', 'основной', 'корпус', 'машинный', 'переводить', 'с', 'английский', 'язык', 'большинство', 'из', 'они', 'быть', 'взять', 'из', 'репозиторий']\n"
     ]
    }
   ],
   "source": [
    "print(list(map(lambda x: x['analysis'][0]['lex'], words_analized_norm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d102a28",
   "metadata": {},
   "source": [
    "## razdel \n",
    "+:\n",
    "1. смог в англ язык\n",
    "\n",
    "-:\n",
    "1. пунктуация входит\n",
    "\n",
    "## mystem\n",
    "\n",
    "+:\n",
    "1. больше информации о токенах\n",
    "1. нет знаков препинания\n",
    "\n",
    "-:\n",
    "1. англ язык\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43063536",
   "metadata": {},
   "source": [
    "# Лемматизация Mystem vs Pymorphy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f15a77e",
   "metadata": {},
   "source": [
    "Лемматизация - это замена словоформы слова в парадигме на какую-то заранее выбранную стадартную форму (лемму).\n",
    "\n",
    "Например, для разных форм глагола леммой обычно является неопределенная форма (инфинитив), а для существительного форма мужского рода единственного числа. Это позволяет избавиться от недостатков стемминга (будет, был - одна лемма), (пролить, пролом - разные). Однако лемматизация значительно сложнее.\n",
    "\n",
    "К счастью есть готовые хорошие лемматизаторы. Для русского основых варианта два: Mystem и Pymorphy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "233c92a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['лично', 'у', 'я', 'классификация', 'на', 'база', 'не', 'особо', 'взлетать', 'например', 'на', 'задача', 'классификация', 'интент', 'классификация']\n"
     ]
    }
   ],
   "source": [
    "print(list(map(lambda x: x['analysis'][0]['lex'], words_analized_norm[:15])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9a66ed86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст:  базе\n",
      "Лемма:  база\n",
      "Грамматика слова:  S,жен,неод=(пр,ед|дат,ед)\n",
      "\"Уверенность\":  0.993192315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'analysis': [{'lex': 'база',\n",
       "   'wt': 0.993192315,\n",
       "   'gr': 'S,жен,неод=(пр,ед|дат,ед)'}],\n",
       " 'text': 'базе'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_info = words_analized_norm[5]\n",
    "print('Текст: ', word_info['text'])\n",
    "print('Лемма: ', word_info['analysis'][0]['lex'])\n",
    "print('Грамматика слова: ', word_info['analysis'][0]['gr'])\n",
    "print('\"Уверенность\": ', word_info['analysis'][0]['wt'])\n",
    "\n",
    "word_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "59be85cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6717b7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='лично', tag=OpencorporaTag('ADVB'), normal_form='лично', score=0.966666, methods_stack=((DictionaryAnalyzer(), 'лично', 3, 0),)),\n",
       " Parse(word='лично', tag=OpencorporaTag('ADJS,Qual neut,sing'), normal_form='личный', score=0.033333, methods_stack=((DictionaryAnalyzer(), 'лично', 12, 29),))]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# основная функция - pymorphy.parse\n",
    "words_analized = [\n",
    "    morph.parse(token) \n",
    "    for token in map(lambda x: x['text'], words_analized_norm)\n",
    "]\n",
    "words_analized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b2e955c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lex': 'лично', 'wt': 0.959131173, 'gr': 'ADV='},\n",
       " {'lex': 'у', 'wt': 0.9993940324, 'gr': 'PR='},\n",
       " {'lex': 'я', 'wt': 0.9999549915, 'gr': 'SPRO,ед,1-л=(вин|род)'},\n",
       " {'lex': 'классификация', 'wt': 1, 'gr': 'S,жен,неод=им,ед'},\n",
       " {'lex': 'на', 'wt': 0.9989522965, 'gr': 'PR='},\n",
       " {'lex': 'база', 'wt': 0.993192315, 'gr': 'S,жен,неод=(пр,ед|дат,ед)'},\n",
       " {'lex': 'не', 'wt': 1, 'gr': 'PART='},\n",
       " {'lex': 'особо', 'wt': 0.9697823395, 'gr': 'ADV='},\n",
       " {'lex': 'взлетать', 'wt': 1, 'gr': 'V,нп=прош,ед,изъяв,жен,сов'},\n",
       " {'lex': 'например', 'wt': 1, 'gr': 'ADV,вводн='},\n",
       " {'lex': 'на', 'wt': 0.9989522965, 'gr': 'PR='},\n",
       " {'lex': 'задача', 'wt': 1, 'gr': 'S,жен,неод=(пр,ед|дат,ед)'},\n",
       " {'lex': 'классификация',\n",
       "  'wt': 1,\n",
       "  'gr': 'S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн)'},\n",
       " {'lex': 'интент', 'wt': 1, 'qual': 'bastard', 'gr': 'S,муж,неод=род,мн'},\n",
       " {'lex': 'классификация', 'wt': 1, 'gr': 'S,жен,неод=им,ед'}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: x['analysis'][0], words_analized_norm[:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f97ba36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='лично', tag=OpencorporaTag('ADVB'), normal_form='лично', score=0.966666, methods_stack=((DictionaryAnalyzer(), 'лично', 3, 0),)),\n",
       " Parse(word='у', tag=OpencorporaTag('PREP'), normal_form='у', score=0.9959, methods_stack=((DictionaryAnalyzer(), 'у', 24, 0),)),\n",
       " Parse(word='меня', tag=OpencorporaTag('NPRO,1per sing,accs'), normal_form='я', score=0.536184, methods_stack=((DictionaryAnalyzer(), 'меня', 3246, 3),)),\n",
       " Parse(word='классификация', tag=OpencorporaTag('NOUN,inan,femn sing,nomn'), normal_form='классификация', score=1.0, methods_stack=((DictionaryAnalyzer(), 'классификация', 41, 0),)),\n",
       " Parse(word='на', tag=OpencorporaTag('PREP'), normal_form='на', score=0.998961, methods_stack=((DictionaryAnalyzer(), 'на', 24, 0),)),\n",
       " Parse(word='базе', tag=OpencorporaTag('NOUN,inan,femn sing,loct'), normal_form='база', score=0.9125, methods_stack=((DictionaryAnalyzer(), 'базе', 55, 6),)),\n",
       " Parse(word='не', tag=OpencorporaTag('PRCL'), normal_form='не', score=1.0, methods_stack=((DictionaryAnalyzer(), 'не', 22, 0),)),\n",
       " Parse(word='особо', tag=OpencorporaTag('ADVB'), normal_form='особо', score=1.0, methods_stack=((DictionaryAnalyzer(), 'особо', 3, 0),)),\n",
       " Parse(word='взлетела', tag=OpencorporaTag('VERB,perf,intr femn,sing,past,indc'), normal_form='взлететь', score=1.0, methods_stack=((DictionaryAnalyzer(), 'взлетела', 791, 2),)),\n",
       " Parse(word='например', tag=OpencorporaTag('CONJ,Prnt'), normal_form='например', score=1.0, methods_stack=((DictionaryAnalyzer(), 'например', 2109, 0),)),\n",
       " Parse(word='на', tag=OpencorporaTag('PREP'), normal_form='на', score=0.998961, methods_stack=((DictionaryAnalyzer(), 'на', 24, 0),)),\n",
       " Parse(word='задаче', tag=OpencorporaTag('NOUN,inan,femn sing,loct'), normal_form='задача', score=0.709677, methods_stack=((DictionaryAnalyzer(), 'задаче', 94, 6),)),\n",
       " Parse(word='классификации', tag=OpencorporaTag('NOUN,inan,femn sing,gent'), normal_form='классификация', score=0.586206, methods_stack=((DictionaryAnalyzer(), 'классификации', 41, 1),)),\n",
       " Parse(word='интентов', tag=OpencorporaTag('NOUN,inan,masc plur,gent'), normal_form='интент', score=0.9881656804733727, methods_stack=((DictionaryAnalyzer(), 'тентов', 34, 7), (UnknownPrefixAnalyzer(score_multiplier=0.5), 'ин'))),\n",
       " Parse(word='классификация', tag=OpencorporaTag('NOUN,inan,femn sing,nomn'), normal_form='классификация', score=1.0, methods_stack=((DictionaryAnalyzer(), 'классификация', 41, 0),))]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: x[0], words_analized[:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68782882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
